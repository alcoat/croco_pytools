{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53297109-7514-4854-ba10-e1777c7f4bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import binary_erosion, binary_dilation\n",
    "from scipy.spatial import cKDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3377aa6-1604-40ad-b2f7-1285849d4c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Répertoires fichiers grilles\n",
    "rep = '/home/thibault-delahaye/git_dev/notebook-grid-tools/DATASETS_CROCOTOOLS/Topo/to_merge_ter/'\n",
    "\n",
    "# Chemins des rasters à fusionner\n",
    "input1 = rep + \"MNT_NC100m_TSUCAL_GEO_refNM_ZNEG_V1.0.grd\" # HIGH RESOLUTION\n",
    "#input2 = rep + \"gebco_2024_n-14.502_s-25.4004_w158.5986_e171.6064.nc\" #LOW RESOLUTION\n",
    "input2= rep + \"etopo_2022_NC.tiff\"\n",
    "\n",
    "# Ouvrir le fichier 1\n",
    "ds1 = xr.open_dataset(input1)\n",
    "ds2 = xr.open_dataset(input2)\n",
    "if input2[-4:]=='tiff':\n",
    "    ds2= ds2.sel(band=1, drop=True)\n",
    "# Identifier la variable contenant les données de bathymétrie\n",
    "# On suppose que la variable de bathymétrie est la seule avec des valeurs numériques\n",
    "for var_name in ds1.data_vars:\n",
    "    var_data = ds1[var_name]\n",
    "    # Vérifier si la variable est 2D et contient des valeurs numériques\n",
    "    if var_data.ndim == 2 and var_data.dtype.kind in {'f', 'i'}:\n",
    "         z_ds1= var_name\n",
    "         break\n",
    "else:\n",
    "    print(\"Aucune variable de bathymétrie trouvée dans ds1\")\n",
    "\n",
    "for var_name in ds2.data_vars:\n",
    "    var_data = ds2[var_name]\n",
    "    # Vérifier si la variable est 2D et contient des valeurs numériques\n",
    "    if var_data.ndim == 2 and var_data.dtype.kind in {'f', 'i'}:\n",
    "         z_ds2= var_name\n",
    "         break\n",
    "else:\n",
    "    print(\"Aucune variable de bathymétrie trouvée dans ds2\")\n",
    "\n",
    "# Identifier les noms des coordonnées lat/lon des fichiers\n",
    "\n",
    "for coord_name in ds1.coords:\n",
    "    coord_data = ds1[coord_name]\n",
    "    # On suppose que lon et lat sont généralement des coordonnées avec des valeurs géographiques\n",
    "    if coord_name.lower() in {'lon', 'longitude'}:\n",
    "        lon_coord_ds1  = coord_name\n",
    "    elif coord_name.lower() in {'lat', 'latitude'}:\n",
    "        lat_coord_ds1  = coord_name\n",
    "    elif coord_data.dims == ('x',) or coord_data.dims == ('y',):\n",
    "        if 'x' in coord_data.dims:\n",
    "            lon_coord_ds1 = coord_name\n",
    "        if 'y' in coord_data.dims:\n",
    "            lat_coord_ds1 = coord_name\n",
    "\n",
    "for coord_name in ds2.coords:\n",
    "    coord_data = ds2[coord_name]\n",
    "    # On suppose que lon et lat sont généralement des coordonnées avec des valeurs géographiques\n",
    "    if coord_name.lower() in {'lon', 'longitude'}:\n",
    "        lon_coord_ds2  = coord_name\n",
    "    elif coord_name.lower() in {'lat', 'latitude'}:\n",
    "        lat_coord_ds2  = coord_name\n",
    "    elif coord_data.dims == ('x',) or coord_data.dims == ('y',):\n",
    "        if 'x' in coord_data.dims:\n",
    "            lon_coord_ds2 = coord_name\n",
    "        if 'y' in coord_data.dims:\n",
    "            lat_coord_ds2 = coord_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28e714c1-9efc-4a51-93d4-8d896dfa9c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interpoler la grille de basse résolution sur une grille de résolution = HIGH RES\n",
    "\n",
    "#Déterminer la résolution de la grille 1\n",
    "resolution_lon= np.diff(ds1[lon_coord_ds1]).mean()\n",
    "resolution_lat= np.diff(ds1[lat_coord_ds1]).mean()\n",
    "\n",
    "lon2= ds2[lon_coord_ds2].values\n",
    "lat2= ds2[lat_coord_ds2].values\n",
    "z2= ds2[z_ds2].values\n",
    "\n",
    "# Récupérér grille ds2 initiale\n",
    "lon_grid_2, lat_grid_2 = np.meshgrid(lon2, lat2)\n",
    "\n",
    "# Aplatir les grilles 2D et les valeurs\n",
    "lon_flat_2 = lon_grid_2.ravel()\n",
    "lat_flat_2 = lat_grid_2.ravel()\n",
    "z_flat_2 = z2.ravel()\n",
    "\n",
    "# Créer une nouvelle grille ds2\n",
    "new_lon_2 = np.arange(lon2.min(), lon2.max(), resolution_lon)\n",
    "new_lat_2 = np.arange(lat2.min(), lat2.max(), resolution_lat)\n",
    "new_lon_grid_2, new_lat_grid_2 = np.meshgrid(new_lon_2, new_lat_2)\n",
    "\n",
    "#INTERPOLATION\n",
    "z2_interp = griddata((lon_flat_2, lat_flat_2), z_flat_2, (new_lon_grid_2, new_lat_grid_2), method='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b65ea2f-f4cf-4f24-845d-e1e782b4868f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon1= ds1[lon_coord_ds1].values\n",
    "lat1= ds1[lat_coord_ds1].values\n",
    "z1= ds1[z_ds1].values\n",
    "\n",
    "# Récupérér grille ds2 initiale\n",
    "lon_grid_1, lat_grid_1 = np.meshgrid(lon1, lat1)\n",
    "\n",
    "# Aplatir les grilles 2D et les valeurs\n",
    "lon_flat_1 = lon_grid_1.ravel()\n",
    "lat_flat_1 = lat_grid_1.ravel()\n",
    "z_flat_1 = z1.ravel()\n",
    "\n",
    "# 1. Identifier la zone de chevauchement entre les grilles\n",
    "lon_min_1, lon_max_1 = lon1.min(), lon1.max()  # Étendue de la grille 1 en longitude\n",
    "lat_min_1, lat_max_1 = lat1.min(), lat1.max()  # Étendue de la grille 1 en latitude\n",
    "\n",
    "# Créer un masque sur la grille rééchantillonnée de la grille 2 qui couvre seulement la zone de la grille 1\n",
    "mask_overlap = (new_lon_grid_2 >= lon_min_1) & (new_lon_grid_2 <= lon_max_1) & \\\n",
    "               (new_lat_grid_2 >= lat_min_1) & (new_lat_grid_2 <= lat_max_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d3bcfcf-064b-4305-9d01-7ca22b98e032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Interpolation des données de la grille 1 (haute résolution) uniquement sur la zone couverte par la grille 1\n",
    "z1_interp_on_z2_overlap = griddata(\n",
    "    (lon_flat_1, lat_flat_1),  # Points d'origine (grille 1)\n",
    "    z_flat_1,                  # Valeurs d'origine (grille 1)\n",
    "    (new_lon_grid_2[mask_overlap], new_lat_grid_2[mask_overlap]),  # Points cibles (zone de la grille 1 dans la grille 2)\n",
    "    method='nearest'           # Méthode d'interpolation\n",
    ")\n",
    "\n",
    "# REMPLACEMENT\n",
    "z2_save= z2_interp.copy()\n",
    "\n",
    "# 3. Remplacer les données de z2_interp uniquement dans la zone de chevauchement avec celles de la grille 1\n",
    "z2_interp[mask_overlap] = z1_interp_on_z2_overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf66330f-de92-48f2-a238-d23055986a8f",
   "metadata": {},
   "source": [
    "### LISSAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a477a1-f573-4127-8c65-7096050d552d",
   "metadata": {},
   "source": [
    "### Lissage des nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21f5c144-cc4e-4450-b94e-7249be8b44a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_buffer_linear_pond(blended_data, low_res_interp, buffer_width):\n",
    "    # Create a mask for NaN values in blended_data where low_res_interp has values\n",
    "    mask_nan = np.isnan(blended_data) & ~np.isnan(low_res_interp)\n",
    "    new_z = blended_data.copy()\n",
    "    \n",
    "    # Create a structuring element of size buffer_width x buffer_width\n",
    "    structure = np.ones((buffer_width, buffer_width), dtype=bool)  # Structuring element for erosion and dilation\n",
    "    \n",
    "    # Apply binary erosion to the NaN mask\n",
    "    mask_eroded = binary_erosion(mask_nan, structure=structure)\n",
    "    \n",
    "    # Apply binary dilation to the eroded mask\n",
    "    mask_dilated = binary_dilation(mask_eroded, structure=structure)\n",
    "    \n",
    "    # Compute the transition mask as the difference between dilated and eroded masks\n",
    "    mask_transition = mask_dilated & ~mask_eroded\n",
    "    \n",
    "    # Compute the interpolation mask for areas not covered by the dilated mask\n",
    "    mask_interpolation = mask_nan & ~mask_dilated\n",
    "    \n",
    "    # Apply binary dilation to the transition mask to expand it\n",
    "    transition_dilated = binary_dilation(mask_transition, structure=np.ones((3, 3)))\n",
    "    # Compute transition borders as the difference between expanded and transition masks\n",
    "    transition_borders = transition_dilated & ~mask_transition\n",
    "    \n",
    "    # Assign low resolution data to the areas covered by the eroded mask\n",
    "    new_z[mask_eroded] = low_res_interp[mask_eroded]  # Low-res data in the eroded zone\n",
    "    \n",
    "    # Get coordinates of transition and transition border areas\n",
    "    coords_mask_transition = np.array(np.where(mask_transition)).T\n",
    "    coords_transition_borders_int = np.array(np.where(transition_borders & mask_eroded)).T\n",
    "    coords_transition_borders_ext = np.array(np.where(transition_borders & ~mask_eroded)).T\n",
    "    \n",
    "    # Build KDTree for internal and external transition borders\n",
    "    tree_transition_borders_int = cKDTree(coords_transition_borders_int)\n",
    "    tree_transition_borders_ext = cKDTree(coords_transition_borders_ext)\n",
    "    \n",
    "    # Compute minimum distances from mask transition coordinates to internal and external borders\n",
    "    distances_int, indices_int = tree_transition_borders_int.query(coords_mask_transition)\n",
    "    distances_ext, indices_ext = tree_transition_borders_ext.query(coords_mask_transition)\n",
    "    \n",
    "    def get_values_from_indices(indices, coords_borders):\n",
    "        # Extract values from z2_combined based on indices\n",
    "        values = np.full(len(indices), np.nan)\n",
    "        for i, idx in enumerate(indices):\n",
    "            if idx < len(coords_borders):\n",
    "                x, y = coords_borders[idx]\n",
    "                values[i] = new_z[x, y]\n",
    "        return values\n",
    "    \n",
    "    # Get values from internal and external border coordinates\n",
    "    values_int = get_values_from_indices(indices_int, coords_transition_borders_int)\n",
    "    values_ext = get_values_from_indices(indices_ext, coords_transition_borders_ext)\n",
    "    \n",
    "    # Compute weighted average for transition values\n",
    "    tot_dist = distances_int + distances_ext\n",
    "    weight_out = distances_int / tot_dist\n",
    "    weight_in = distances_ext / tot_dist\n",
    "    ponderated_transition = weight_in * values_int + weight_out * values_ext\n",
    "    \n",
    "    def apply_ponderated_values(new_z, mask_transition, ponderated_values, coords_mask_transition):\n",
    "        # Apply weighted values to z2_combined based on transition mask\n",
    "        for i, (coord, value) in enumerate(zip(coords_mask_transition, ponderated_values)):\n",
    "            x, y = coord\n",
    "            if mask_transition[x, y]:\n",
    "                new_z[x, y] = value\n",
    "        return new_z\n",
    "    \n",
    "    # Apply weighted values to the combined matrix\n",
    "    new_z = apply_ponderated_values(new_z, mask_transition, ponderated_transition, coords_mask_transition)\n",
    "\n",
    "    return new_z, mask_transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b2e87d7-3786-47e3-8eff-e9839d9178b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "[z_less_nan, mask_buff_nan_10]= nan_buffer_linear_pond(z2_interp, z2_save, buffer_width=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6455c9a-a08a-4e60-b7b7-fd51a5142770",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(z_less_nan).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48c1cbf3-5388-437d-a827-9a47ceb0f827",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_less_nan_2, mask_buff_nan_3= nan_buffer_linear_pond(z_less_nan, z2_save, buffer_width=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c50e48f-b8a7-4a0b-823e-48e94ef62376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37085"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(z_less_nan_2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d4fbb57-f3db-40a0-9b09-ab23ea0a5bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_less_nan_3, mask_buff_nan_3= nan_buffer_linear_pond(z_less_nan_2, z2_save, buffer_width=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be92bb9e-e80e-44bf-aebe-891471f6d025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19752"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(z_less_nan_3).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8906045e-7891-4df8-9840-be6915bcaa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_less_nan_bis, mask_buff_nan_3= nan_buffer_linear_pond(z_less_nan_3, z2_save, buffer_width=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76b143a3-b906-4678-80ba-19345ede5bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8911"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(z_less_nan_bis).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16b09868-ff16-4897-bef7-eab0148eb6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.247814081804558e-05"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8911/96357906"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7b8652-d275-4c8a-a921-5fd9be251174",
   "metadata": {},
   "source": [
    "### INTERPOLATION DES DERNIERS NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14de3da9-c8eb-4d3e-bd35-059b6391f0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyinterp.backends.xarray\n",
    "# Module that handles the filling of undefined values.\n",
    "import pyinterp.fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7b3007b-adc7-46af-beaa-c902e7ddea8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyinterp\n",
    "\n",
    "# Données d'exemple\n",
    "lon_flat_2 = np.ravel(new_lon_grid_2)\n",
    "lat_flat_2 = np.ravel(new_lat_grid_2)\n",
    "#z_flat_2 = np.ravel(z_less_nan_bis)\n",
    "\n",
    "# Masque des NaN\n",
    "#mask_nan = np.isnan(z_flat_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d495230-b60c-4f61-86e3-7bd7c0b0d4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer des axes pour les coordonnées\n",
    "lon_axis = pyinterp.Axis(np.unique(lon_flat_2))\n",
    "lat_axis = pyinterp.Axis(np.unique(lat_flat_2))\n",
    "\n",
    "# Créer une grille 2D vide\n",
    "grid_data = np.full((len(lat_axis), len(lon_axis)), np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6397833-441a-4e2f-a85f-f26299ff164b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pyinterp.Grid2D(lat_axis,lon_axis,z2_interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79b1be71-5ab4-4e62-86ec-0fc5b3d9447a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un objet Grid2D avec les axes\n",
    "data = pyinterp.Grid2D(lat_axis,lon_axis,z_less_nan_bis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93018670-ee57-49bc-966b-bba25db220b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pyinterp' has no attribute 'fill'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[43mpyinterp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[38;5;241m.\u001b[39mloess(data, nx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, ny\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pyinterp' has no attribute 'fill'"
     ]
    }
   ],
   "source": [
    "z = pyinterp.fill.loess(data, nx=3, ny=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cebbd412-f550-45e8-843a-117a2dd2c488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3cb5f482-62ad-472f-b68c-8863d210af99",
   "metadata": {},
   "source": [
    "### LISSAGE DE LA ZONE TAMPON INTER_GRILLES (RECTANGLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c417b652-b8d6-4007-83ea-7ffbab8441f0",
   "metadata": {},
   "source": [
    "#### Création du masque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a9b1225a-15e1-42d0-87c8-c702f5731958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avertissement : Pas de place pour un buffer sur le côté haut. Aucun lissage.\n",
      "Top: 0, Bottom: 7379, Left: 2146, Right: 9045\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Dimensions de la grille\n",
    "grid_shape = new_lon_grid_2.shape\n",
    "\n",
    "# Obtenir les indices des positions où le masque de recouvrement est True\n",
    "true_indices = np.array(np.where(mask_overlap))\n",
    "\n",
    "# Obtenir les coordonnées des 4 extrémités du mask_overlap\n",
    "top = true_indices[0].min()   # Coordonnée de la première ligne avec True (haut)\n",
    "bottom = true_indices[0].max()  # Coordonnée de la dernière ligne avec True (bas)\n",
    "left = true_indices[1].min()  # Coordonnée de la première colonne avec True (gauche)\n",
    "right = true_indices[1].max()  # Coordonnée de la dernière colonne avec True (droite)\n",
    "\n",
    "# Largeur du tampon\n",
    "buffer_width = 30  # Exemple\n",
    "min_buffer_width = 3  # Largeur minimum du tampon\n",
    "\n",
    "# Initialiser un masque tampon vide\n",
    "mask_buffer = np.zeros(grid_shape, dtype=bool)\n",
    "\n",
    "# Fonction pour créer un tampon si la distance au bord est suffisante\n",
    "def create_buffer_on_side(start_idx, end_idx, buffer_limit, buffer_width, max_limit, side):\n",
    "    if buffer_limit <= min_buffer_width:  # Pas assez de place pour un tampon propre\n",
    "        print(f\"Avertissement : Pas de place pour un buffer sur le côté {side}. Aucun lissage.\")\n",
    "        return 0\n",
    "    elif buffer_limit < buffer_width:  # Réduire la taille du tampon\n",
    "        print(f\"Avertissement : Le buffer sur le côté {side} a été réduit à {buffer_limit} mailles.\")\n",
    "        buffer_width = buffer_limit\n",
    "    return buffer_width\n",
    "\n",
    "# Fonction pour vérifier les données numériques en dehors du tampon\n",
    "def has_valid_data_outside(start_row, end_row, start_col, end_col):\n",
    "    return np.any(new_lon_grid_2[start_row:end_row, start_col:end_col])\n",
    "\n",
    "# Créer le tampon uniquement sur les côtés où le mask_overlap n'est pas trop près des bords\n",
    "# et s'assurer qu'il y a de la donnée valide pour interpoler.\n",
    "\n",
    "# Si le haut du mask_overlap n'est pas sur le bord haut de la grille\n",
    "buffer_top = create_buffer_on_side(top, bottom, top, buffer_width, grid_shape[0], \"haut\")\n",
    "if buffer_top > 0 and has_valid_data_outside(top-buffer_top, top, left, right+1): \n",
    "    mask_buffer[top - buffer_top:top, left:right+1] = True\n",
    "\n",
    "# Si le bas du mask_overlap n'est pas sur le bord bas de la grille\n",
    "buffer_bottom = create_buffer_on_side(bottom, bottom+buffer_width, grid_shape[0]-bottom-1, buffer_width, grid_shape[0], \"bas\")\n",
    "if buffer_bottom > 0 and has_valid_data_outside(bottom+1, bottom+1+buffer_bottom, left, right+1): \n",
    "    mask_buffer[bottom+1:bottom+1+buffer_bottom, left:right+1] = True\n",
    "\n",
    "# Si la gauche du mask_overlap n'est pas sur le bord gauche de la grille\n",
    "buffer_left = create_buffer_on_side(left, right, left, buffer_width, grid_shape[1], \"gauche\")\n",
    "if buffer_left > 0 and has_valid_data_outside(top, bottom+1, left-buffer_left, left): \n",
    "    mask_buffer[top:bottom+1, left-buffer_left:left] = True\n",
    "\n",
    "# Si la droite du mask_overlap n'est pas sur le bord droit de la grille\n",
    "buffer_right = create_buffer_on_side(right, right+buffer_width, grid_shape[1]-right-1, buffer_width, grid_shape[1], \"droite\")\n",
    "if buffer_right > 0 and has_valid_data_outside(top, bottom+1, right+1, right+1+buffer_right): \n",
    "    mask_buffer[top:bottom+1, right+1:right+1+buffer_right] = True\n",
    "\n",
    "# Inclure les coins si nécessaire\n",
    "def include_corners(mask_buffer, top, bottom, left, right, buffer_width):\n",
    "    # Coin supérieur gauche\n",
    "    if top - buffer_width >= 0 and left - buffer_width >= 0:\n",
    "        mask_buffer[top - buffer_width:top, left - buffer_width:left] = True\n",
    "    # Coin supérieur droit\n",
    "    if top - buffer_width >= 0 and right + buffer_width < grid_shape[1]:\n",
    "        mask_buffer[top - buffer_width:top, right + 1:right + 1 + buffer_width] = True\n",
    "    # Coin inférieur gauche\n",
    "    if bottom + buffer_width < grid_shape[0] and left - buffer_width >= 0:\n",
    "        mask_buffer[bottom + 1:bottom + 1 + buffer_width, left - buffer_width:left] = True\n",
    "    # Coin inférieur droit\n",
    "    if bottom + buffer_width < grid_shape[0] and right + buffer_width < grid_shape[1]:\n",
    "        mask_buffer[bottom + 1:bottom + 1 + buffer_width, right + 1:right + 1 + buffer_width] = True\n",
    "\n",
    "include_corners(mask_buffer, top, bottom, left, right, buffer_width)\n",
    "\n",
    "# Exclure la zone de recouvrement du tampon\n",
    "mask_buffer[mask_overlap] = False\n",
    "\n",
    "# Afficher les coordonnées ajustées pour la zone tampon\n",
    "print(f'Top: {top}, Bottom: {bottom}, Left: {left}, Right: {right}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b409c1e8-7323-4ef3-936a-54cd23538c4c",
   "metadata": {},
   "source": [
    "#### Création des bordures du masque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "18c41184-4c3e-41d5-b97c-e605b95ec81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dilated_mask_buffer= binary_dilation(mask_buffer)\n",
    "border_buffer_ext = dilated_mask_buffer & ~mask_buffer & ~mask_overlap\n",
    "border_buffer_inner = mask_overlap & dilated_mask_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "af69d228-c5ee-43cf-aa9a-fbf146489eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LEBOn\n",
    "# Get coordinates of borders and buffer\n",
    "coords_border_inner = np.array(np.where(border_buffer_inner)).T\n",
    "coords_border_outer = np.array(np.where(border_buffer_ext)).T\n",
    "coords_buffer = np.array(np.where(mask_buffer)).T\n",
    "\n",
    "# Get values from z2_interp at the border points\n",
    "values_inner = z_less_nan_bis[border_buffer_inner]\n",
    "values_outer = z_less_nan_bis[border_buffer_ext]\n",
    "\n",
    "# Build KDTree for inner and outer borders\n",
    "tree_border_inner = cKDTree(coords_border_inner)\n",
    "tree_border_outer = cKDTree(coords_border_outer)\n",
    "\n",
    "# Initialize array for interpolated values\n",
    "interpolated_values_buffer = np.zeros(len(coords_buffer))\n",
    "\n",
    "# For each point in the buffer, find nearest border points\n",
    "for i, coord in enumerate(coords_buffer):\n",
    "    # Query the KDTree for nearest points\n",
    "    dist_inner, idx_inner = tree_border_inner.query(coord)\n",
    "    dist_outer, idx_outer = tree_border_outer.query(coord)\n",
    "    \n",
    "    # Extract values of nearest border points\n",
    "    value_inner = values_inner[idx_inner]\n",
    "    value_outer = values_outer[idx_outer]\n",
    "    \n",
    "    # Calculate total distance and weights\n",
    "    total_distance = dist_inner + dist_outer\n",
    "    if total_distance == 0:\n",
    "        # Handle the case where total distance is zero\n",
    "        print(f\"Warning: Total distance is zero for point {coord}\")\n",
    "        interpolated_values_buffer[i] = np.nan\n",
    "    else:\n",
    "        weight_inner = dist_outer / total_distance\n",
    "        weight_outer = dist_inner / total_distance\n",
    "        \n",
    "        # Calculate interpolated value\n",
    "        interpolated_values_buffer[i] = weight_inner * value_inner + weight_outer * value_outer\n",
    "\n",
    "# Check for NaNs in interpolated_values_buffer\n",
    "if np.any(np.isnan(interpolated_values_buffer)):\n",
    "    print(f\"NaNs found in interpolated_values_buffer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0fbb36a8-a5c4-4747-9ad0-90d5da1fcbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "z[mask_buffer] = interpolated_values_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a8303490-e626-4fb2-90da-6fcc72c9b4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "# Obtenez les coordonnées uniques\n",
    "new_lon_unique = np.unique(new_lon_grid_2)\n",
    "new_lat_unique = np.unique(new_lat_grid_2)\n",
    "\n",
    "# Créer un DataArray pour les données interpolées\n",
    "ds_interpolated = xr.DataArray(\n",
    "    z, \n",
    "    coords=[('lat', new_lat_unique), ('lon', new_lon_unique)],  # Ajouter les coordonnées\n",
    "    dims=['lat', 'lon']  # Spécifier les dimensions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c3d60555-1962-49e0-a3f1-96be93155271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un Dataset pour organiser les variables\n",
    "ds_to_save = xr.Dataset({\n",
    "    'z': ds_interpolated  # Ajouter la variable interpolée\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e5c851a0-1db9-44e3-ade0-0877acd7f084",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_to_save.to_netcdf('composite_etopo_jroger_FINAL_3.nc', encoding={'z': {'chunksizes': (100, 100)}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eda247-1b61-4d87-8c32-4c925921e8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Créer un Dataset pour organiser les variables\n",
    "ds_to_save = xr.Dataset({\n",
    "    'z2_interp': ds_interpolated  # Ajouter la variable interpolée\n",
    "})\n",
    "\n",
    "# Sauvegarder dans un fichier NetCDF\n",
    "ds_to_save.to_netcdf('composite_etopo_jroger_FINAL.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c27aa8-dfb8-4238-b9a5-48553b5f4b94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
